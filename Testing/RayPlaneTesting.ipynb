{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5. -0. -0.]\n"
     ]
    }
   ],
   "source": [
    "## RAY TO PLANE INTERSECTION BROKEN DOWN\n",
    "import numpy as np\n",
    "\n",
    "def ray_to_plane_intersection(u, R, T, l):\n",
    "    \"\"\"\n",
    "    Calculates the intersection of a ray with a plane in a structured light camera system.\n",
    "\n",
    "    :param u: Image point coordinates as a numpy array [u1, u2, 1].\n",
    "    :param R: Rotation matrix of the camera.\n",
    "    :param T: Translation vector of the camera.\n",
    "    :param l: Vector defining the line on the image plane.\n",
    "\n",
    "    :return: Intersection point in world coordinates.\n",
    "    \"\"\"\n",
    "    # Converting to homogeneous coordinates\n",
    "    u = np.append(u, [1])\n",
    "\n",
    "    # Calculate q (center of projection in world coordinates)\n",
    "    q = -np.dot(R.T, T)\n",
    "\n",
    "    # Calculate v (direction vector in world coordinates)\n",
    "    v = np.dot(R.T, u)\n",
    "\n",
    "    # Calculate n (normal vector of the plane in world coordinates)\n",
    "    n = np.dot(R.T, l)\n",
    "\n",
    "    # Solve for lambda in the plane equation: n^t * (q + lambda * v - q) = 0\n",
    "    # Simplified to: lambda = -n^t * q / n^t * v\n",
    "    lambda_val = -np.dot(n.T, q) / np.dot(n.T, v)\n",
    "\n",
    "    # Calculate the intersection point\n",
    "    intersection_point = q + lambda_val * v\n",
    "\n",
    "    return intersection_point\n",
    "\n",
    "# Example usage\n",
    "u = np.array([100, 200])  # Example image point coordinates\n",
    "R = np.eye(3)            # Example rotation matrix (identity matrix)\n",
    "T = np.array([5, 0, 0]) # Example translation vector\n",
    "l = np.array([0, 1, -5]) # Example line vector (horizontal line)\n",
    "\n",
    "# Calculate the intersection point\n",
    "intersection_point = ray_to_plane_intersection(u, R, T, l)\n",
    "print(intersection_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def generate_gray_code_patterns(width, height):\n",
    "    \"\"\"\n",
    "    :param width: Projector Width\n",
    "    :param Height: Projector Height\n",
    "    \"\"\"\n",
    "    # Calculate number of bits required to represent the width\n",
    "    num_bits = math.ceil(math.log2(width))\n",
    "    # Calculate the offset to center the pattern\n",
    "    offset = (2 ** num_bits - width) // 2\n",
    "\n",
    "    # Initialize pattern storage\n",
    "    pattern = np.zeros((height, width, num_bits), dtype=np.uint8)\n",
    "    directory = \"C:\\\\Users\\\\nludw\\\\Documents\\\\Capstone\\\\Binary Coding\\\\GrayCodedPictures\"  # Change to Pi directory\n",
    "    # Generate binary and Gray code numbers\n",
    "    binary_numbers = np.array([list(format(i, '0' + str(num_bits) + 'b')) for i in range(2 ** num_bits)], dtype=np.uint8)\n",
    "    gray_codes = np.bitwise_xor(binary_numbers[:, :-1], binary_numbers[:, 1:]) #XOR bitwise for gray coding\n",
    "    gray_codes = np.c_[binary_numbers[:, 0], gray_codes]  # Add the first bit back\n",
    "    \n",
    "    # Fill in the pattern\n",
    "    for i in range(num_bits):\n",
    "        pattern[:, :, i] = np.tile(gray_codes[(np.arange(width) + offset), i].reshape(1, -1), (height, 1))\n",
    "        filename = \"gray_pattern{}.png\".format(i)\n",
    "        cv.imwrite(directory + \"\\\\\" + filename, 255*pattern[:,:,i]) #Need to multiply by 255 for openCV to save as white\n",
    "    blankImage = np.zeros((height,width), dtype=np.uint8)\n",
    "    fullImage = 255*np.ones((height,width),dtype=np.uint8)\n",
    "    cv.imwrite(directory + \"\\\\blankImage.png\", blankImage)\n",
    "    cv.imwrite(directory + \"\\\\fullImage.png\", fullImage)\n",
    "        \n",
    "    return pattern, offset\n",
    "\n",
    "\n",
    "def convert_gray_code_to_decimal(gray_code_patterns):\n",
    "    height, width, num_bits = gray_code_patterns.shape\n",
    "    # num_bits -= 1 ### DELETE THIS AFTER TESTING\n",
    "    binary_patterns = np.zeros((height, width, num_bits), dtype=np.uint8)\n",
    "    binary_patterns[:, :, 0] = gray_code_patterns[:, :, 0]\n",
    "    for i in range(1, num_bits):\n",
    "        binary_patterns[:, :, i] = np.bitwise_xor(binary_patterns[:, :, i-1], gray_code_patterns[:, :, i])\n",
    "        \n",
    "    decimal_values = np.zeros((height, width), dtype=int)\n",
    "    for i in range(num_bits):\n",
    "        decimal_values += (2 ** (num_bits - 1 - i)) * binary_patterns[:, :, i]\n",
    "    decimal_values += 1\n",
    "    decimal_values -= int(64) # adjust decimal values according to aspect ratio to get columns 1 through 1920 (should be 64 for 1920 by 1080, 224 for 1600 by 1200). \n",
    "    return decimal_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_3D_points(decoded_image, camera_matrix, R, T, projector_intrinsics):\n",
    "    height, width = decoded_image.shape\n",
    "    points_3D = np.zeros((height, width, 3))\n",
    "\n",
    "    # Define the normal to the projector planes (pointing in the x direction)\n",
    "    plane_normal = np.array([1, 0, 0])\n",
    "    points_3D = []\n",
    "    # Iterate over each pixel in the decoded image\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            projector_column = decoded_image[i, j]\n",
    "            if projector_column <= 0:\n",
    "                continue  # Skip invalid points\n",
    "\n",
    "            # Image point in pixel coordinates\n",
    "            u = np.array([j, i])  # 2D pixel coordinates\n",
    "\n",
    "            # Convert the projector column index to world coordinatess\n",
    "            projector_point_homogeneous = np.linalg.inv(projector_intrinsics).dot(np.array([projector_column, 0, 1]))\n",
    "            projector_point_3D = projector_point_homogeneous[:3] / projector_point_homogeneous[2]\n",
    "            plane_distance = projector_point_3D[0]  # Assuming distance is along the x-axis\n",
    "\n",
    "            # Calculate the intersection point using the ray_to_plane_intersection function\n",
    "            intersection_point = ray_to_plane_intersection(u, camera_matrix, R, T, plane_normal, plane_distance)\n",
    "            if np.any(intersection_point): points_3D.append(intersection_point)\n",
    "\n",
    "    return points_3D\n",
    "\n",
    "\n",
    "\n",
    "def ray_to_plane_intersection(u, camera_matrix, R, T, plane_normal, plane_distance):\n",
    "\n",
    "    # Convert image point to normalized camera coordinates\n",
    "    u_normalized = np.linalg.inv(camera_matrix).dot(np.append(u, 1))\n",
    "\n",
    "    # Calculate q (center of projection in world coordinates)\n",
    "    q = -np.dot(R.T, T)\n",
    "\n",
    "    # Calculate v (direction vector in world coordinates)\n",
    "    v = np.dot(R.T, u_normalized)\n",
    "\n",
    "    # Define the plane equation: n * (X - d * n) = 0\n",
    "    # Calculate the intersection point\n",
    "    lambda_val = (plane_distance - np.dot(plane_normal, q)) / np.dot(plane_normal, v)\n",
    "    intersection_point = q + lambda_val * v\n",
    "\n",
    "    return intersection_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pbpthreshold(image,threshold):\n",
    "    \"\"\"\n",
    "    :param image: Input image.\n",
    "    :param threshold: Threshold image.\n",
    "    \"\"\"\n",
    "    #Compares image to thresholding image, set binary, if < than threshold image pixel = 0, if >, pixel goes to 255.\n",
    "    flatimage = image.flatten()\n",
    "    flatthreshold = threshold.flatten()\n",
    "    if len(image) != len(threshold):\n",
    "        print(\"Image and Threshold Matrix are incompatible sizes\")\n",
    "        return\n",
    "    for i in range(len(flatimage)):\n",
    "        if flatimage[i] <= flatthreshold[i]:\n",
    "            flatimage[i] = 0\n",
    "        elif flatimage[i] > flatthreshold[i]:\n",
    "            flatimage[i] = 1\n",
    "            \n",
    "    image = flatimage.reshape(image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def visualize_point_cloud(points_3D):\n",
    "\n",
    "    # Convert the points to an open3d point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points_3D)\n",
    "    o3d.visualization.draw_geometries([point_cloud])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Camera intrinsic matrix for a simple pinhole camera model\n",
    "focal_length = 1000\n",
    "camera_matrix = np.array([[focal_length, 0, 500],\n",
    "                          [0, focal_length, 500],\n",
    "                          [0, 0, 1]])\n",
    "\n",
    "projector_matrix = np.array([[focal_length, 0, 500],\n",
    "                             [0, focal_length, 500],\n",
    "                             [0, 0, 1]])\n",
    "\n",
    "\n",
    "# Camera extrinsic parameters - assuming aligned with the world coordinates\n",
    "R = np.eye(3)  # Identity matrix for rotation\n",
    "T = np.array([-1000, 0, 0])  # Translation along Z-axis\n",
    "\n",
    "# Simulated decoded image from structured light system\n",
    "decoded_image = np.tile(np.arange(10), (1000, 1))  # 1000x1000 image with values from 0 to 9\n",
    "\n",
    "# Calculate the 3D points\n",
    "points_3D = calculate_3D_points(decoded_image, camera_matrix, R, T, projector_matrix)\n",
    "\n",
    "# Check a few points\n",
    "  # Print 3D points for a few columns at the middle row\n",
    "visualize_point_cloud(points_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "width = 1600\n",
    "height = 1200\n",
    "grayPattern, offsets = generate_gray_code_patterns(width, height)\n",
    "\n",
    "blankImage = cv.imread(\"testImages/blank_image.png\")\n",
    "fullImage = cv.imread(\"testImages/full_image.png\") \n",
    "\n",
    "blankImage = cv.cvtColor(blankImage, cv.COLOR_BGR2GRAY)/255\n",
    "fullImage = cv.cvtColor(fullImage,cv.COLOR_BGR2GRAY)/255\n",
    "image_array = np.empty((grayPattern.shape[2],fullImage.shape[0],fullImage.shape[1]), dtype=grayPattern.dtype)\n",
    "avg_thresh = cv.addWeighted(blankImage,0.5,fullImage,0.5,0) #add white and blank images for thresholding and average\n",
    "\n",
    "\n",
    "\n",
    "# Viewing the patterns\n",
    "# cv2.imshow('Pattern', grayPattern[:,:,0] * 255)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(grayPattern.shape[2]-1):\n",
    "\n",
    "    # load image array and pre-process images\n",
    "    filein = \"testImages/image_{}.png\".format(i+1)\n",
    "    image = cv.imread(filein)\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)/255\n",
    "    #Convert to black and white based on grascale (average per pixel thresholding)\n",
    "    image_thresh = pbpthreshold(image_gray,avg_thresh)\n",
    "    image_array[i] = image_thresh\n",
    "    captured_patterns = np.transpose(image_array,(1,2,0)) #reorder shape for binary decoding \n",
    "\n",
    "# cv.imshow('book',image_array[4]*255)\n",
    "# cv.waitKey(0)\n",
    "# Convert Gray code to decimal\n",
    "# col_values = convert_gray_code_to_decimal(captured_patterns)\n",
    "# print(col_values)\n",
    "# col_values = convert_gray_code_to_decimal(grayPattern)\n",
    "# print(col_values)\n",
    "# decoded_image = convert_gray_code_to_decimal(captured_patterns)\n",
    "\n",
    "\n",
    "# K = np.array([[1642.17076,0,1176.14705],[0, 1642.83775, 714.90826],[0,0,1]])\n",
    "# R = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "# t = np.array([[0],[0],[1]])\n",
    "# P_proj = np.array([[1642.17076,0,0],[0,1642.83775,0],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an image mask from the full Image to block out shadows and non projected regions\n",
    "\n",
    "\n",
    "\n",
    "def overlay_mask_with_threshold(image1, image2, threshold=10):\n",
    "  \n",
    "    # Ensure the images are the same size\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Images must have the same dimensions\")\n",
    "\n",
    "    # Compute the absolute difference between the images\n",
    "    diff = cv.absdiff(image1, image2)\n",
    "\n",
    "    # Convert difference to grayscale\n",
    "    gray_diff = cv.cvtColor(diff, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create a mask where the difference is below the threshold (similar pixels)\n",
    "    _, mask = cv.threshold(gray_diff, threshold, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "    # Create a red overlay\n",
    "    red_overlay = np.zeros_like(image1, image1.dtype)\n",
    "    red_overlay[:, :] = [0, 0, 255]  # Red color\n",
    "\n",
    "    # Apply the mask to the red overlay\n",
    "    red_mask = cv.bitwise_and(red_overlay, red_overlay, mask=mask)\n",
    "\n",
    "    # Overlay the red mask on the original image\n",
    "    overlay_result = cv.addWeighted(image1, 1, red_mask, 1, 0)\n",
    "\n",
    "    # Display the result\n",
    "    cv.imshow('Red Overlay on Image with Threshold', overlay_result)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    return mask\n",
    "\n",
    "    # Optionally, save the result\n",
    "    # cv2.imwrite('overlay_threshold_result.jpg', overlay_result)\n",
    "\n",
    "# Example usage\n",
    "# blankImage = cv.imread(\"C:\\\\Users\\\\nludw\\\\Documents\\\\Capstone\\\\Binary Coding\\\\Testing\\\\TestImages\\\\blankImage.png\")\n",
    "# fullImage = cv.imread(\"C:\\\\Users\\\\nludw\\\\Documents\\\\Capstone\\\\Binary Coding\\\\Testing\\\\TestImages\\\\fullImage.png\") \n",
    "# mask = overlay_mask_with_threshold(fullImage, blankImage, threshold=5)\n",
    "# print(mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"testImages/\"\n",
    "width = 1920\n",
    "height = 1080\n",
    "grayPattern, offsets = generate_gray_code_patterns(width, height)\n",
    "\n",
    "blankImage = cv.imread(directory+\"blank_image.png\")\n",
    "fullImage = cv.imread(directory+\"full_image.png\")\n",
    "blankImage = cv.cvtColor(blankImage, cv.COLOR_BGR2GRAY)/255\n",
    "fullImage = cv.cvtColor(fullImage,cv.COLOR_BGR2GRAY)/255\n",
    "image_array = np.empty((grayPattern.shape[2],fullImage.shape[0],fullImage.shape[1]), dtype=grayPattern.dtype)\n",
    "avg_thresh = cv.addWeighted(blankImage,0.5,fullImage,0.5,0) #add white and blank images for thresholding and average\n",
    "\n",
    "\n",
    "for i in range(grayPattern.shape[2]-1):\n",
    "\n",
    "    # load image array and pre-process images\n",
    "    filein = \"image_{}.png\".format(i+1)\n",
    "    image = cv.imread(directory+filein)\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)/255\n",
    "    #Convert to black and white based on grascale (average per pixel thresholding)\n",
    "    image_thresh = pbpthreshold(image_gray,avg_thresh)\n",
    "    image_array[i] = image_thresh\n",
    "    captured_patterns = np.transpose(image_array,(1,2,0)) #reorder shape for binary decoding \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "blankImage = cv.imread(directory+\"blank_image.png\")\n",
    "fullImage = cv.imread(directory+\"full_image.png\")\n",
    "mask = overlay_mask_with_threshold(fullImage, blankImage, threshold=50)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# K = np.array([[1642.17076,0,1176.14705],[0, 1642.83775, 714.90826],[0,0,1]])\n",
    "# R = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "# t = np.array([[0],[0],[1]])\n",
    "# P_proj = np.array([[1642.17076,0,0],[0,1642.83775,0],[0,0,1]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
