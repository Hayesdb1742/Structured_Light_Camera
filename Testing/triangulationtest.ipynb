{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_plane_intersection(decoded_gray_image, camera_matrix, projector_matrix, rotation_matrix, translation_vector):\n",
    "    # Make sure the translation vector is a column vector\n",
    "    print(\"ray_plane_intersection\")\n",
    "    if translation_vector.ndim == 1 or translation_vector.shape[0] == 1:\n",
    "        translation_vector = translation_vector.reshape(3, 1)\n",
    "    height, width = decoded_gray_image.shape[:2]\n",
    "    \n",
    "    # Generate a grid of (u, v) coordinates\n",
    "    u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    u = u.flatten()\n",
    "    v = v.flatten()\n",
    "    proj_cols = decoded_gray_image.flatten()\n",
    "    \n",
    "    # Filter out invalid column indices\n",
    "    valid_cols = proj_cols >= 0\n",
    "    u_valid = u[valid_cols]\n",
    "    v_valid = v[valid_cols]\n",
    "    proj_cols_valid = proj_cols[valid_cols]\n",
    "    \n",
    "    # Normalize pixel coordinates to camera space\n",
    "    camera_points_normalized = np.linalg.inv(camera_matrix).dot(\n",
    "        np.vstack((u_valid, v_valid, np.ones_like(u_valid)))\n",
    "    )\n",
    "    \n",
    "    # Projector points in homogeneous coordinates\n",
    "    projector_points_homogeneous = np.vstack((proj_cols_valid, np.zeros_like(proj_cols_valid), np.ones_like(proj_cols_valid)))\n",
    "    # Convert projector points to 3D space in camera coordinates\n",
    "    projector_points_3D = np.linalg.inv(projector_matrix).dot(projector_points_homogeneous)\n",
    "    projector_points_3D /= projector_points_3D[2, :]  # Normalize z to 1\n",
    "    \n",
    "    # Concatenate rotation matrix and translation vector to form the extrinsic matrix\n",
    "    extrinsic_matrix = np.hstack((rotation_matrix, translation_vector))\n",
    "    \n",
    "    # Transform projector points to camera coordinate system\n",
    "    projector_points_camera_coords = extrinsic_matrix.dot(\n",
    "        np.vstack((projector_points_3D[:3, :], np.ones(projector_points_3D.shape[1])))\n",
    "    )\n",
    "    # Assuming the planes are perpendicular to the projector's y-axis\n",
    "    plane_normal_projector = np.array([0, 1, 0])  # Normal along Y-axis for vertical stripes\n",
    "    plane_normal_camera = rotation_matrix.dot(plane_normal_projector)\n",
    "    # Ray directions for each camera point\n",
    "    ray_directions = camera_points_normalized[:3, :] - np.zeros((3, 1))  # Camera origin is (0, 0, 0)\n",
    "\n",
    "    # Calculate ray-plane intersections\n",
    "    dot_normals = plane_normal_camera.T.dot(ray_directions)\n",
    "    valid_rays = dot_normals != 0  # Avoid division by zero\n",
    "    # Calculating intersection 't' for each ray\n",
    "    t = np.zeros(dot_normals.shape)\n",
    "    t[valid_rays] = (plane_normal_camera.T.dot(projector_points_camera_coords[:3, :] - translation_vector)) / dot_normals[valid_rays]\n",
    "\n",
    "    # Intersection points in camera coordinates\n",
    "    intersection_points = ray_directions * t + np.zeros((3, 1))  # Adding camera origin\n",
    "    # Prepare the output array\n",
    "    points_3D = np.zeros((height * width, 3))\n",
    "    points_3D[valid_cols, :] = intersection_points.T  # Transpose to match the shape\n",
    "    points_3D = points_3D.reshape((height, width, 3))\n",
    "    \n",
    "    return points_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistortPoints(src,dst,cameraMatrix,distCoeffs):\n",
    "    \"\"\"\n",
    "    :param src: Input Distorted Image.\n",
    "    :param dst: Output Corrected image with same size and type as src.\n",
    "    :param CameraMatrix: Intrinsic camera Matrix K\n",
    "    :param distCoeffs: distortion coefficients (k1,k2,p1,p2,[k3]) of 4,5, or 8 elements.\n",
    "    :return: undistorted image.\n",
    "    \"\"\"\n",
    "    image = cv.undistort(src,dst,cameraMatrix,distCoeffs)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_point_cloud(points_3D):\n",
    "    print(\"visualize_point_cloud\")\n",
    "    points = points_3D.reshape(-1, 3) # Convert points from 3D matrix to list of 3D coordinates\n",
    "    points = points[np.any(points != [0, 0, 0], axis=1)] # Filter out zero points\n",
    "    \n",
    "    print(\"open3d\")\n",
    "    # Convert the points to an open3d point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    print(\"pc generated\")\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    print(\"points generated\")\n",
    "    o3d.visualization.draw_geometries([point_cloud])\n",
    "\n",
    "    \n",
    "# def createMesh(points,radius=1.0,iterations=100,confidence=0.9): ##Might want to use open3D instead\n",
    "#     \"\"\"\n",
    "#         :param points: 3D points\n",
    "#         :param radius: Optional, default=1\n",
    "#         :param iterations: Optional, default=100\n",
    "#         :param confidence: Optional, default=0.9\n",
    "#     \"\"\"\n",
    "#     # Compute the normals for the point cloud\n",
    "#     normals = cv.computeNormals(points)\n",
    "#     # Create the surface mesh\n",
    "#     mesh = cv.surfaceReconstruction(points, normals, radius, iterations, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gray_code_patterns(width, height):\n",
    "    \"\"\"\n",
    "    :param width: Projector Width\n",
    "    :param Height: Projector Height\n",
    "    \"\"\"\n",
    "    # Calculate number of bits required to represent the width\n",
    "    num_bits = math.ceil(math.log2(width))\n",
    "    # Calculate the offset to center the pattern\n",
    "    offset = (2 ** num_bits - width) // 2\n",
    "\n",
    "    # Initialize pattern storage\n",
    "    pattern = np.zeros((height, width, num_bits), dtype=np.uint8)\n",
    "    directory = \"C:\\\\Users\\\\nludw\\\\Documents\\\\Capstone\\\\Binary Coding\\\\GrayCodedPictures\"  # Change to Pi directory\n",
    "    # Generate binary and Gray code numbers\n",
    "    binary_numbers = np.array([list(format(i, '0' + str(num_bits) + 'b')) for i in range(2 ** num_bits)], dtype=np.uint8)\n",
    "    gray_codes = np.bitwise_xor(binary_numbers[:, :-1], binary_numbers[:, 1:]) #XOR bitwise for gray coding\n",
    "    gray_codes = np.c_[binary_numbers[:, 0], gray_codes]  # Add the first bit back\n",
    "    \n",
    "    # Fill in the pattern\n",
    "    for i in range(num_bits):\n",
    "        pattern[:, :, i] = np.tile(gray_codes[(np.arange(width) + offset), i].reshape(1, -1), (height, 1))\n",
    "        filename = \"gray_pattern{}.png\".format(i)\n",
    "        cv.imwrite(directory + \"\\\\\" + filename, 255*pattern[:,:,i]) #Need to multiply by 255 for openCV to save as white\n",
    "    blankImage = np.zeros((height,width), dtype=np.uint8)\n",
    "    fullImage = 255*np.ones((height,width),dtype=np.uint8)\n",
    "    cv.imwrite(directory + \"\\\\blankImage.png\", blankImage)\n",
    "    cv.imwrite(directory + \"\\\\fullImage.png\", fullImage)\n",
    "        \n",
    "    return pattern, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gray_code_to_decimal(gray_code_patterns):\n",
    "    print(\"convert to gray code\")\n",
    "    height, width, num_bits = gray_code_patterns.shape\n",
    "    # num_bits -= 1 ### DELETE THIS AFTER TESTING\n",
    "    binary_patterns = np.zeros((height, width, num_bits), dtype=np.uint8)\n",
    "    binary_patterns[:, :, 0] = gray_code_patterns[:, :, 0]\n",
    "    for i in range(1, num_bits):\n",
    "        binary_patterns[:, :, i] = np.bitwise_xor(binary_patterns[:, :, i-1], gray_code_patterns[:, :, i])\n",
    "        \n",
    "    decimal_values = np.zeros((height, width), dtype=int)\n",
    "    for i in range(num_bits):\n",
    "        decimal_values += (2 ** (num_bits - 1 - i)) * binary_patterns[:, :, i]\n",
    "    decimal_values += 1\n",
    "    decimal_values -= int(224) # adjust decimal values according to aspect ratio to get columns 1 through 1920 (should be 64 for 1920 by 1080, 224 for 1600 by 1200). \n",
    "    return decimal_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbpthreshold(image,threshold):\n",
    "    \"\"\"\n",
    "    :param image: Input image.\n",
    "    :param threshold: Threshold image.\n",
    "    \"\"\"\n",
    "    #Compares image to thresholding image, set binary, if < than threshold image pixel = 0, if >, pixel goes to 255.\n",
    "    flatimage = image.flatten()\n",
    "    flatthreshold = threshold.flatten()\n",
    "    if len(image) != len(threshold):\n",
    "        print(\"Image and Threshold Matrix are incompatible sizes\")\n",
    "        return\n",
    "    for i in range(len(flatimage)):\n",
    "        if flatimage[i] <= flatthreshold[i]:\n",
    "            flatimage[i] = 0\n",
    "        elif flatimage[i] > flatthreshold[i]:\n",
    "            flatimage[i] = 1\n",
    "            \n",
    "    image = flatimage.reshape(image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1600\n",
    "height = 1200\n",
    "grayPattern, offsets = generate_gray_code_patterns(width, height)\n",
    "\n",
    "blankImage = cv.imread(\"blankImage.bmp\")//255 #to convert from 0-255 to 0-1\n",
    "fullImage = cv.imread(\"fullImage.bmp\")//255\n",
    "blankImage = cv.cvtColor(blankImage, cv.COLOR_BGR2GRAY)\n",
    "fullImage = cv.cvtColor(fullImage,cv.COLOR_BGR2GRAY)\n",
    "image_array = np.empty((grayPattern.shape[2],fullImage.shape[0],fullImage.shape[1]), dtype=grayPattern.dtype)\n",
    "avg_thresh = cv.addWeighted(blankImage,0.5,fullImage,0.5,0) #add white and blank images for thresholding and average\n",
    "avg_thresh = cv.divide(avg_thresh,2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Viewing the patterns\n",
    "cv.imshow('Pattern', grayPattern[:,:,3] * 255)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.bmp\n",
      "2.bmp\n",
      "3.bmp\n",
      "4.bmp\n",
      "5.bmp\n",
      "6.bmp\n",
      "7.bmp\n",
      "8.bmp\n",
      "9.bmp\n",
      "10.bmp\n",
      "[[[1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]]\n",
      "\n",
      " [[1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]]\n",
      "\n",
      " [[1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]]\n",
      "\n",
      " [[1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]]\n",
      "\n",
      " [[1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]\n",
      "  [1 1 1 ... 1 1 0]]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(grayPattern.shape[2]-1):\n",
    "\n",
    "    # load image array and pre-process images\n",
    "    filein = \"{}.bmp\".format(i+1)\n",
    "    print(filein)\n",
    "    image = cv.imread(filein)\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    #Convert to black and white based on grascale (average per pixel thresholding)\n",
    "    image_thresh = pbpthreshold(image_gray,avg_thresh)\n",
    "    image_array[i] = image_thresh\n",
    "    captured_patterns = np.transpose(image_array,(1,2,0)) #reorder shape for binary decoding \n",
    "\n",
    "print(captured_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to gray code\n",
      "[[1141 1141 1141 ... 1141 1141 1141]\n",
      " [1141 1141 1141 ... 1141 1141 1141]\n",
      " [1141 1141 1141 ... 1141 1141 1141]\n",
      " ...\n",
      " [1141 1141 1141 ... 1141 1141 1141]\n",
      " [1141 1141 1141 ... 1141 1141 1141]\n",
      " [1141 1141 1141 ... 1141 1141 1141]]\n",
      "convert to gray code\n",
      "[[   1    2    3 ... 1598 1599 1600]\n",
      " [   1    2    3 ... 1598 1599 1600]\n",
      " [   1    2    3 ... 1598 1599 1600]\n",
      " ...\n",
      " [   1    2    3 ... 1598 1599 1600]\n",
      " [   1    2    3 ... 1598 1599 1600]\n",
      " [   1    2    3 ... 1598 1599 1600]]\n",
      "convert to gray code\n",
      "(1200, 1600) (1200, 1600)\n"
     ]
    }
   ],
   "source": [
    "col_values = convert_gray_code_to_decimal(captured_patterns)\n",
    "print(col_values)\n",
    "col_values = convert_gray_code_to_decimal(grayPattern)\n",
    "print(col_values)\n",
    "decoded_image = convert_gray_code_to_decimal(captured_patterns)\n",
    "\n",
    "\n",
    "K = np.array([[1642.17076,0,1176.14705],[0, 1642.83775, 714.90826],[0,0,1]])\n",
    "R = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "t = np.array([[0],[0],[1]])\n",
    "P_proj = np.array([[1642.17076,0,0],[0,1642.83775,0],[0,0,1]])\n",
    "\n",
    "print(col_values.shape,decoded_image.shape)\n",
    "# points_3D = ray_plane_intersection(decoded_image,K,P_proj,R,t)\n",
    "# print(points_3D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_gray_image, camera_matrix, projector_matrix, rotation_matrix, translation_vector = decoded_image,K,P_proj,R,t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray_plane_intersection\n"
     ]
    }
   ],
   "source": [
    "print(\"ray_plane_intersection\")\n",
    "if translation_vector.ndim == 1 or translation_vector.shape[0] == 1:\n",
    "    translation_vector = translation_vector.reshape(3, 1)\n",
    "height, width = decoded_gray_image.shape[:2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.71621483 -0.71560588 -0.71499693 ...  0.25627843  0.25688738\n",
      "   0.25749633]\n",
      " [-0.43516669 -0.43516669 -0.43516669 ...  0.29466802  0.29466802\n",
      "   0.29466802]\n",
      " [ 1.          1.          1.         ...  1.          1.\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    " # Generate a grid of (u, v) coordinates\n",
    "u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "u = u.flatten()\n",
    "v = v.flatten()\n",
    "proj_cols = decoded_gray_image.flatten()\n",
    "\n",
    "# Filter out invalid column indices\n",
    "valid_cols = proj_cols >= 0\n",
    "u_valid = u[valid_cols]\n",
    "v_valid = v[valid_cols]\n",
    "proj_cols_valid = proj_cols[valid_cols]\n",
    "\n",
    "# Normalize pixel coordinates to camera space\n",
    "camera_points_normalized = np.linalg.inv(camera_matrix).dot(\n",
    "    np.vstack((u_valid, v_valid, np.ones_like(u_valid)))\n",
    ")\n",
    "print(camera_points_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Projector points in homogeneous coordinates\n",
    "projector_points_homogeneous = np.vstack((proj_cols_valid, np.zeros_like(proj_cols_valid), np.ones_like(proj_cols_valid)))\n",
    "# Convert projector points to 3D space in camera coordinates\n",
    "projector_points_3D = np.linalg.inv(projector_matrix).dot(projector_points_homogeneous)\n",
    "projector_points_3D /= projector_points_3D[2, :]  # Normalize z to 1\n",
    "\n",
    "# Concatenate rotation matrix and translation vector to form the extrinsic matrix\n",
    "extrinsic_matrix = np.hstack((rotation_matrix, translation_vector))\n",
    "print(extrinsic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.71621483 -0.71560588 -0.71499693 ...  0.25627843  0.25688738\n",
      "   0.25749633]\n",
      " [-0.43516669 -0.43516669 -0.43516669 ...  0.29466802  0.29466802\n",
      "   0.29466802]\n",
      " [ 1.          1.          1.         ...  1.          1.\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    " # Transform projector points to camera coordinate system\n",
    "projector_points_camera_coords = extrinsic_matrix.dot(\n",
    "    np.vstack((projector_points_3D[:3, :], np.ones(projector_points_3D.shape[1])))\n",
    ")\n",
    "# Assuming the planes are perpendicular to the projector's y-axis\n",
    "plane_normal_projector = np.array([0, 1, 0])  # Normal along Y-axis for vertical stripes\n",
    "plane_normal_camera = rotation_matrix.dot(plane_normal_projector)\n",
    "# Ray directions for each camera point\n",
    "ray_directions = camera_points_normalized[:3, :] - np.zeros((3, 1))  # Camera origin is (0, 0, 0)\n",
    "print(ray_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.43516669 -0.43516669 -0.43516669 ... -0.00055286 -0.00055286\n",
      " -0.00055286]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1920000,) (1144000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46880\\3077381007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print((projector_points_camera_coords[:3, :] - translation_vector))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_normals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_rays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_rays\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mplane_normal_camera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojector_points_camera_coords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtranslation_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdot_normals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_rays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1920000,) (1144000,) "
     ]
    }
   ],
   "source": [
    "# Calculate ray-plane intersections\n",
    "dot_normals = plane_normal_camera.T.dot(ray_directions)\n",
    "valid_rays = dot_normals < 0 # Avoid division by zero\n",
    "# Calculating intersection 't' for each ray\n",
    "t = np.zeros(dot_normals.shape)\n",
    "# print((projector_points_camera_coords[:3, :] - translation_vector))\n",
    "print(dot_normals[valid_rays])\n",
    "t[valid_rays] = (plane_normal_camera.T.dot(projector_points_camera_coords[:3, :] - translation_vector)) / dot_normals[valid_rays]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Intersection points in camera coordinates\n",
    "intersection_points = ray_directions * t + np.zeros((3, 1))  # Adding camera origin\n",
    "# Prepare the output array\n",
    "points_3D = np.zeros((height * width, 3))\n",
    "points_3D[valid_cols, :] = intersection_points.T  # Transpose to match the shape\n",
    "points_3D = points_3D.reshape((height, width, 3))\n",
    "print(points_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 0 points."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = points_3D.reshape(-1, 3)\n",
    "points = points[np.any(points != [0, 0, 0], axis=1)]\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "point_cloud\n",
    "# o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_point_cloud(points_3D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
