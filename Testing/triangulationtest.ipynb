{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_plane_intersection(decoded_gray_image, camera_matrix, projector_matrix, rotation_matrix, translation_vector):\n",
    "    # Make sure the translation vector is a column vector\n",
    "    print(\"ray_plane_intersection\")\n",
    "    if translation_vector.ndim == 1 or translation_vector.shape[0] == 1:\n",
    "        translation_vector = translation_vector.reshape(3, 1)\n",
    "    height, width = decoded_gray_image.shape[:2]\n",
    "    \n",
    "    # Generate a grid of (u, v) coordinates\n",
    "    u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    u = u.flatten()\n",
    "    v = v.flatten()\n",
    "    proj_cols = decoded_gray_image.flatten()\n",
    "    \n",
    "    # Filter out invalid column indices\n",
    "    valid_cols = proj_cols >= 0\n",
    "    u_valid = u[valid_cols]\n",
    "    v_valid = v[valid_cols]\n",
    "    proj_cols_valid = proj_cols[valid_cols]\n",
    "    \n",
    "    # Normalize pixel coordinates to camera space\n",
    "    camera_points_normalized = np.linalg.inv(camera_matrix).dot(\n",
    "        np.vstack((u_valid, v_valid, np.ones_like(u_valid)))\n",
    "    )\n",
    "    \n",
    "    # Projector points in homogeneous coordinates\n",
    "    projector_points_homogeneous = np.vstack((proj_cols_valid, np.zeros_like(proj_cols_valid), np.ones_like(proj_cols_valid)))\n",
    "    # Convert projector points to 3D space in camera coordinates\n",
    "    projector_points_3D = np.linalg.inv(projector_matrix).dot(projector_points_homogeneous)\n",
    "    projector_points_3D /= projector_points_3D[2, :]  # Normalize z to 1\n",
    "    \n",
    "    # Concatenate rotation matrix and translation vector to form the extrinsic matrix\n",
    "    extrinsic_matrix = np.hstack((rotation_matrix, translation_vector))\n",
    "    \n",
    "    # Transform projector points to camera coordinate system\n",
    "    projector_points_camera_coords = extrinsic_matrix.dot(\n",
    "        np.vstack((projector_points_3D[:3, :], np.ones(projector_points_3D.shape[1])))\n",
    "    )\n",
    "    # Assuming the planes are perpendicular to the projector's y-axis\n",
    "    plane_normal_projector = np.array([0, 1, 0])  # Normal along Y-axis for vertical stripes\n",
    "    plane_normal_camera = rotation_matrix.dot(plane_normal_projector)\n",
    "    # Ray directions for each camera point\n",
    "    ray_directions = camera_points_normalized[:3, :] - np.zeros((3, 1))  # Camera origin is (0, 0, 0)\n",
    "\n",
    "    # Calculate ray-plane intersections\n",
    "    dot_normals = plane_normal_camera.T.dot(ray_directions)\n",
    "    valid_rays = dot_normals != 0  # Avoid division by zero\n",
    "    # Calculating intersection 't' for each ray\n",
    "    t = np.zeros(dot_normals.shape)\n",
    "    t[valid_rays] = (plane_normal_camera.T.dot(projector_points_camera_coords[:3, :] - translation_vector)) / dot_normals[valid_rays]\n",
    "\n",
    "    # Intersection points in camera coordinates\n",
    "    intersection_points = ray_directions * t + np.zeros((3, 1))  # Adding camera origin\n",
    "    # Prepare the output array\n",
    "    points_3D = np.zeros((height * width, 3))\n",
    "    points_3D[valid_cols, :] = intersection_points.T  # Transpose to match the shape\n",
    "    points_3D = points_3D.reshape((height, width, 3))\n",
    "    \n",
    "    return points_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistortPoints(src,dst,cameraMatrix,distCoeffs):\n",
    "    \"\"\"\n",
    "    :param src: Input Distorted Image.\n",
    "    :param dst: Output Corrected image with same size and type as src.\n",
    "    :param CameraMatrix: Intrinsic camera Matrix K\n",
    "    :param distCoeffs: distortion coefficients (k1,k2,p1,p2,[k3]) of 4,5, or 8 elements.\n",
    "    :return: undistorted image.\n",
    "    \"\"\"\n",
    "    image = cv.undistort(src,dst,cameraMatrix,distCoeffs)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_point_cloud(points_3D):\n",
    "    print(\"visualize_point_cloud\")\n",
    "    points = points_3D.reshape(-1, 3) # Convert points from 3D matrix to list of 3D coordinates\n",
    "    points = points[np.any(points != [0, 0, 0], axis=1)] # Filter out zero points\n",
    "    \n",
    "    print(\"open3d\")\n",
    "    # Convert the points to an open3d point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    print(\"pc generated\")\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    print(\"points generated\")\n",
    "    \n",
    "    o3d.visualization.draw_geometries_with_editing([point_cloud])\n",
    "\n",
    "    \n",
    "# def createMesh(points,radius=1.0,iterations=100,confidence=0.9): ##Might want to use open3D instead\n",
    "#     \"\"\"\n",
    "#         :param points: 3D points\n",
    "#         :param radius: Optional, default=1\n",
    "#         :param iterations: Optional, default=100\n",
    "#         :param confidence: Optional, default=0.9\n",
    "#     \"\"\"\n",
    "#     # Compute the normals for the point cloud\n",
    "#     normals = cv.computeNormals(points)\n",
    "#     # Create the surface mesh\n",
    "#     mesh = cv.surfaceReconstruction(points, normals, radius, iterations, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTest(points_3D):\n",
    "    # Create a random point cloud for demonstration\n",
    "    points = points_3D.reshape(-1, 3) # Convert points from 3D matrix to list of 3D coordinates\n",
    "    print(points.shape)\n",
    "    points = points[np.any(points != [0, 0, 0], axis=1)] # Filter out zero points\n",
    "\n",
    "    # Convert the points to an open3d point cloud object\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    print(\"pc generated\")\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # Create a set of coordinate axes with a larger size\n",
    "    axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1.0, origin=[0, 0, 0])\n",
    "\n",
    "    # Combine the point cloud and the axes into a list of geometries\n",
    "    geometries = [point_cloud, axes]\n",
    "\n",
    "    # Visualize the combined geometries\n",
    "    o3d.visualization.draw_geometries(geometries)\n",
    "\n",
    "    \n",
    "# def createMesh(points,radius=1.0,iterations=100,confidence=0.9): ##Might want to use open3D instead\n",
    "#     \"\"\"\n",
    "#         :param points: 3D points\n",
    "#         :param radius: Optional, default=1\n",
    "#         :param iterations: Optional, default=100\n",
    "#         :param confidence: Optional, default=0.9\n",
    "#     \"\"\"\n",
    "#     # Compute the normals for the point cloud\n",
    "#     normals = cv.computeNormals(points)\n",
    "#     # Create the surface mesh\n",
    "#     mesh = cv.surfaceReconstruction(points, normals, radius, iterations, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gray_code_patterns(width, height):\n",
    "    \"\"\"\n",
    "    :param width: Projector Width\n",
    "    :param Height: Projector Height\n",
    "    \"\"\"\n",
    "    # Calculate number of bits required to represent the width\n",
    "    num_bits = math.ceil(math.log2(width))\n",
    "    # Calculate the offset to center the pattern\n",
    "    offset = (2 ** num_bits - width) // 2\n",
    "\n",
    "    # Initialize pattern storage\n",
    "    pattern = np.zeros((height, width, num_bits), dtype=np.uint8)\n",
    "    directory = \"C:\\\\Users\\\\nludw\\\\Documents\\\\Capstone\\\\Binary Coding\\\\GrayCodedPictures\"  # Change to Pi directory\n",
    "    # Generate binary and Gray code numbers\n",
    "    binary_numbers = np.array([list(format(i, '0' + str(num_bits) + 'b')) for i in range(2 ** num_bits)], dtype=np.uint8)\n",
    "    gray_codes = np.bitwise_xor(binary_numbers[:, :-1], binary_numbers[:, 1:]) #XOR bitwise for gray coding\n",
    "    gray_codes = np.c_[binary_numbers[:, 0], gray_codes]  # Add the first bit back\n",
    "    \n",
    "    # Fill in the pattern\n",
    "    for i in range(num_bits):\n",
    "        pattern[:, :, i] = np.tile(gray_codes[(np.arange(width) + offset), i].reshape(1, -1), (height, 1))\n",
    "        filename = \"gray_pattern{}.png\".format(i)\n",
    "        cv.imwrite(directory + \"\\\\\" + filename, 255*pattern[:,:,i]) #Need to multiply by 255 for openCV to save as white\n",
    "    blankImage = np.zeros((height,width), dtype=np.uint8)\n",
    "    fullImage = 255*np.ones((height,width),dtype=np.uint8)\n",
    "    cv.imwrite(directory + \"\\\\blankImage.png\", blankImage)\n",
    "    cv.imwrite(directory + \"\\\\fullImage.png\", fullImage)\n",
    "        \n",
    "    return pattern, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gray_code_to_decimal(gray_code_patterns):\n",
    "    print(\"convert to gray code\")\n",
    "    height, width, num_bits = gray_code_patterns.shape\n",
    "    # num_bits -= 1 ### DELETE THIS AFTER TESTING\n",
    "    binary_patterns = np.zeros((height, width, num_bits), dtype=np.uint8)\n",
    "    binary_patterns[:, :, 0] = gray_code_patterns[:, :, 0]\n",
    "    for i in range(1, num_bits):\n",
    "        binary_patterns[:, :, i] = np.bitwise_xor(binary_patterns[:, :, i-1], gray_code_patterns[:, :, i])\n",
    "        \n",
    "    decimal_values = np.zeros((height, width), dtype=int)\n",
    "    for i in range(num_bits):\n",
    "        decimal_values += (2 ** (num_bits - 1 - i)) * binary_patterns[:, :, i]\n",
    "    decimal_values += 1\n",
    "    decimal_values -= int(224) # adjust decimal values according to aspect ratio to get columns 1 through 1920 (should be 64 for 1920 by 1080, 224 for 1600 by 1200). \n",
    "    return decimal_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbpthreshold(image,threshold):\n",
    "    \"\"\"\n",
    "    :param image: Input image.\n",
    "    :param threshold: Threshold image.\n",
    "    \"\"\"\n",
    "    #Compares image to thresholding image, set binary, if < than threshold image pixel = 0, if >, pixel goes to 255.\n",
    "    flatimage = image.flatten()\n",
    "    flatthreshold = threshold.flatten()\n",
    "    if len(image) != len(threshold):\n",
    "        print(\"Image and Threshold Matrix are incompatible sizes\")\n",
    "        return\n",
    "    for i in range(len(flatimage)):\n",
    "        if flatimage[i] <= flatthreshold[i]:\n",
    "            flatimage[i] = 0\n",
    "        elif flatimage[i] > flatthreshold[i]:\n",
    "            flatimage[i] = 1\n",
    "            \n",
    "    image = flatimage.reshape(image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1600\n",
    "height = 1200\n",
    "grayPattern, offsets = generate_gray_code_patterns(width, height)\n",
    "\n",
    "blankImage = cv.imread(\"blankImage.bmp\") #to convert from 0-255 to 0-1\n",
    "fullImage = cv.imread(\"fullImage.bmp\")\n",
    "blankImage = cv.cvtColor(blankImage, cv.COLOR_BGR2GRAY)\n",
    "fullImage = cv.cvtColor(fullImage,cv.COLOR_BGR2GRAY)\n",
    "image_array = np.empty((grayPattern.shape[2],fullImage.shape[0],fullImage.shape[1]), dtype=grayPattern.dtype)\n",
    "avg_thresh = cv.addWeighted(blankImage,0.5,fullImage,0.5,0) #add white and blank images for thresholding and average\n",
    "avg_thresh = cv.divide(avg_thresh,2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Viewing the patterns\n",
    "# cv.imshow('Pattern', grayPattern[:,:,3] * 255)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(grayPattern.shape[2]-1):\n",
    "\n",
    "    # load image array and pre-process images\n",
    "    filein = \"{}.bmp\".format(i+1)\n",
    "    image = cv.imread(filein)\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    #Convert to black and white based on grascale (average per pixel thresholding)\n",
    "    image_thresh = pbpthreshold(image_gray,avg_thresh)\n",
    "    image_array[i] = image_thresh\n",
    "    captured_patterns = np.transpose(image_array,(1,2,0)) #reorder shape for binary decoding \n",
    "\n",
    "# print(captured_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to gray code\n",
      "convert to gray code\n",
      "convert to gray code\n",
      "(1200, 1600) (1200, 1600)\n"
     ]
    }
   ],
   "source": [
    "col_values = convert_gray_code_to_decimal(captured_patterns)\n",
    "col_values = convert_gray_code_to_decimal(grayPattern)\n",
    "decoded_image = convert_gray_code_to_decimal(captured_patterns)\n",
    "\n",
    "#Chnaged values\n",
    "# K = np.array([[1642.17076,0,1176.14705],[0, 1642.83775, 714.90826],[0,0,1]])\n",
    "# R = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "# t = np.array([[0],[0],[1]])\n",
    "# P_proj = np.array([[1642.17076,0,0],[0,1642.83775,0],[0,0,1]])\n",
    "\n",
    "K = np.array([[1315.17076,0,795.14705],[0, 1320.8212, 587.90826],[0,0,1]])\n",
    "R = np.array([[.92,.029,-.38],[-.088,0.986,-.13],[.379,.160,.912]])\n",
    "t = np.array([[151.996],[-55.6],[296.37]])\n",
    "P_proj = np.array([[1315.45,0,795],[0,1320.83775,587.33],[0,0,1]])\n",
    "\n",
    "\n",
    "print(col_values.shape,decoded_image.shape)\n",
    "# points_3D = ray_plane_intersection(decoded_image,K,P_proj,R,t)\n",
    "# print(points_3D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_gray_image, camera_matrix, projector_matrix, rotation_matrix, translation_vector = decoded_image,K,P_proj,R,t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray_plane_intersection\n"
     ]
    }
   ],
   "source": [
    "print(\"ray_plane_intersection\")\n",
    "if translation_vector.ndim == 1 or translation_vector.shape[0] == 1:\n",
    "    translation_vector = translation_vector.reshape(3, 1)\n",
    "height, width = decoded_gray_image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generate a grid of (u, v) coordinates\n",
    "u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "u = u.flatten()\n",
    "v = v.flatten()\n",
    "proj_cols = decoded_gray_image.flatten()\n",
    "# Filter out invalid column indices\n",
    "valid_cols = proj_cols >= 0\n",
    "u_valid = u[valid_cols]\n",
    "v_valid = v[valid_cols]\n",
    "proj_cols_valid = proj_cols[valid_cols]\n",
    "# Normalize pixel coordinates to camera space\n",
    "camera_points_normalized = np.linalg.inv(camera_matrix).dot(\n",
    "    np.vstack((u_valid, v_valid, np.ones_like(u_valid)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.20000e-01  2.90000e-02 -3.80000e-01  1.51996e+02]\n",
      " [-8.80000e-02  9.86000e-01 -1.30000e-01 -5.56000e+01]\n",
      " [ 3.79000e-01  1.60000e-01  9.12000e-01  2.96370e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Projector points in homogeneous coordinates\n",
    "projector_points_homogeneous = np.vstack((proj_cols_valid, np.zeros_like(proj_cols_valid), np.ones_like(proj_cols_valid)))\n",
    "# Convert projector points to 3D space in camera coordinates\n",
    "projector_points_3D = np.linalg.inv(projector_matrix).dot(projector_points_homogeneous)\n",
    "projector_points_3D /= projector_points_3D[2, :]  # Normalize z to 1\n",
    "\n",
    "# Concatenate rotation matrix and translation vector to form the extrinsic matrix\n",
    "extrinsic_matrix = np.hstack((rotation_matrix, translation_vector))\n",
    "print(extrinsic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751460,)\n"
     ]
    }
   ],
   "source": [
    " # Transform projector points to camera coordinate system\n",
    "projector_points_camera_coords = extrinsic_matrix.dot(\n",
    "    np.vstack((projector_points_3D[:3, :], np.ones(projector_points_3D.shape[1])))\n",
    ")\n",
    "# Assuming the planes are perpendicular to the projector's y-axis\n",
    "plane_normal_projector = np.array([0, 1, 0])  # Normal along Y-axis for vertical stripes\n",
    "plane_normal_camera = rotation_matrix.dot(plane_normal_projector)\n",
    "print(plane_normal_camera.T.dot(projector_points_camera_coords[:3, :]).shape)\n",
    "# Ray directions for each camera point\n",
    "ray_directions = camera_points_normalized[:3, :] - np.zeros((3, 1))  # Camera origin is (0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[151.90593645 151.66604896 151.66604896 ... 151.84509035 151.84509035\n",
      "  151.84509035]\n",
      " [-56.19740597 -56.17446021 -56.17446021 ... -56.1915859  -56.1915859\n",
      "  -56.1915859 ]\n",
      " [297.33560714 297.23678393 297.23678393 ... 297.3105412  297.3105412\n",
      "  297.3105412 ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate ray-plane intersections\n",
    "dot_normals = plane_normal_camera.T.dot(ray_directions)\n",
    "\n",
    "valid_rays = abs(dot_normals) > 1e-10 # Avoid division by zero\n",
    "# Calculating intersection 't' for each ray\n",
    "t = np.zeros(dot_normals.shape)\n",
    "print(projector_points_camera_coords[:3, :])\n",
    "t[valid_rays] = (plane_normal_camera.T.dot(projector_points_camera_coords[:3, :] - translation_vector)) / dot_normals[valid_rays]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.60459605 -0.6038357  -0.60307534 ...  0.60969493  0.61045529\n",
      "   0.61121565]\n",
      " [-0.44510813 -0.44510813 -0.44510813 ...  0.46266046  0.46266046\n",
      "   0.46266046]\n",
      " [ 1.          1.          1.         ...  1.          1.\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Intersection points in camera coordinates\n",
    "print(ray_directions)\n",
    "intersection_points = ray_directions * t + np.zeros((3, 1))  # Adding camera origin\n",
    "# Prepare the output array\n",
    "points_3D = np.zeros((height * width, 3))\n",
    "points_3D[valid_cols, :] = intersection_points.T  # Transpose to match the shape\n",
    "points_3D = points_3D.reshape((height, width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of values above 0: 17.29%\n",
      "Percentage of values below 0: 82.71%\n"
     ]
    }
   ],
   "source": [
    "points = points_3D.reshape(-1, 3)\n",
    "points = points[np.any(points != [0, 0, 0], axis=1)]\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "\n",
    "threshold = 0\n",
    "col = points[:,1]\n",
    "above_threshold_count = np.sum(col > threshold)\n",
    "below_threshold_count = np.sum(col < threshold)\n",
    "\n",
    "total_count = col.size\n",
    "above_threshold_percentage = (above_threshold_count / total_count) * 100\n",
    "below_threshold_percentage = (below_threshold_count / total_count) * 100\n",
    "\n",
    "# Print the percentages\n",
    "print(f\"Percentage of values above {threshold}: {above_threshold_percentage:.2f}%\")\n",
    "print(f\"Percentage of values below {threshold}: {below_threshold_percentage:.2f}%\")\n",
    "# o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualize_point_cloud\n",
      "(1920000, 3)\n",
      "open3d\n",
      "pc generated\n",
      "points generated\n"
     ]
    }
   ],
   "source": [
    "visualizeTest(points_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[30 31 35]\n",
      "  [36 35 22]\n",
      "  [27 19 10]\n",
      "  ...\n",
      "  [ 4  4  7]\n",
      "  [ 3  4  7]\n",
      "  [ 3  3  7]]\n",
      "\n",
      " [[33 30 32]\n",
      "  [40 28 22]\n",
      "  [29 21 13]\n",
      "  ...\n",
      "  [ 4  4  7]\n",
      "  [ 4  5  6]\n",
      "  [ 4  5  7]]\n",
      "\n",
      " [[32 31 29]\n",
      "  [40 23 22]\n",
      "  [28 20 15]\n",
      "  ...\n",
      "  [ 4  4  6]\n",
      "  [ 3  4  6]\n",
      "  [ 3  6  7]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[33 35 18]\n",
      "  [37 19 14]\n",
      "  [23 11 11]\n",
      "  ...\n",
      "  [ 6  8 13]\n",
      "  [ 6  9 13]\n",
      "  [ 6  8 13]]\n",
      "\n",
      " [[38 33 18]\n",
      "  [37 17 14]\n",
      "  [24 11 11]\n",
      "  ...\n",
      "  [ 6  9 13]\n",
      "  [ 6  9 13]\n",
      "  [ 6  9 13]]\n",
      "\n",
      " [[44 31 19]\n",
      "  [38 18 15]\n",
      "  [24 11 11]\n",
      "  ...\n",
      "  [ 6  8 13]\n",
      "  [ 6  9 14]\n",
      "  [ 6  9 14]]]\n",
      "(1200, 3)\n",
      "(1200, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load the depth image from a BMP file\n",
    "depth_image = cv.imread('10.bmp', cv.IMREAD_UNCHANGED)\n",
    "print(depth_image)\n",
    "# Step 2: Assuming you have intrinsic camera parameters (fx, fy, cx, cy)\n",
    "fx = 525.0  # Focal length in x direction\n",
    "fy = 525.0  # Focal length in y direction\n",
    "\n",
    "# Get the dimensions of the depth \n",
    "rows, cols, depth = depth_image.shape\n",
    "\n",
    "# Calculate the principal point\n",
    "cx = cols / 2.0\n",
    "cy = rows / 2.0\n",
    "cz = depth /2.0\n",
    "\n",
    "# Create an array of pixel coordinates\n",
    "c, r, d = np.meshgrid(np.arange(cols), np.arange(rows), np.arange(depth))\n",
    "z = depth_image / 500.0  # Scale factor, adjust as needed\n",
    "# Compute 3D coordinates (x, y, z) using depth and intrinsic parameters\n",
    "# x = (c - cx) * z / fx\n",
    "# y = (r - cy) * z / fy\n",
    "# Stack the x, y, and z coordinates to create a (N, 3) array\n",
    "depth_scale = 0.001\n",
    "depth_values = depth_image[:,2] * depth_scale\n",
    "x = np.array(depth_image[:,0])\n",
    "y = np.array(depth_image[:,1])\n",
    "print(y.shape)\n",
    "\n",
    "point_cloud = np.stack((x, y,depth_values), axis=-1)\n",
    "print(point_cloud.shape)\n",
    "# Step 3: Create an Open3D PointCloud and populate it with the 3D points\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "# pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "\n",
    "# # Step 4: Visualize the point cloud using Open3D\n",
    "# o3d.visualization.draw_geometries([pcd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
